# Documentation ComplÃ¨te - SystÃ¨me de Recommandation de Films

Ce document consolide toute la documentation du projet en un seul fichier de rÃ©fÃ©rence.

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture](#architecture)
3. [Installation et DÃ©marrage](#installation-et-dÃ©marrage)
4. [Structure du Projet](#structure-du-projet)
5. [Connexions entre Services](#connexions-entre-services)
6. [Step 1: Data Contracts](#step-1-data-contracts)
7. [Step 2: Bootstrap Bronze Layer](#step-2-bootstrap-bronze-layer)
8. [Scripts Utilitaires](#scripts-utilitaires)
9. [Exemples de Code](#exemples-de-code)
10. [Configuration](#configuration)
11. [Monitoring](#monitoring)
12. [DÃ©pannage](#dÃ©pannage)
13. [Prochaines Ã‰tapes](#prochaines-Ã©tapes)

---

## Vue d'ensemble

Ce projet implÃ©mente un systÃ¨me de recommandation de films utilisant un Ã©cosystÃ¨me Big Data complet avec Docker. Le systÃ¨me traite des donnÃ©es de films, gÃ©nÃ¨re des recommandations personnalisÃ©es et fournit une API pour servir les rÃ©sultats.

### Objectifs

- Traitement distribuÃ© de grandes quantitÃ©s de donnÃ©es (MovieLens 25M)
- Streaming de donnÃ©es en temps rÃ©el via Kafka
- GÃ©nÃ©ration de recommandations personnalisÃ©es (ALS)
- DÃ©tection de tendances en temps rÃ©el
- API REST pour servir les recommandations
- Monitoring et observabilitÃ© complets

---

## Architecture

### Composants Principaux

| Service | Port | Description |
|---------|------|-------------|
| **Kafka** | 9092 | Streaming de donnÃ©es en temps rÃ©el |
| **Kafka UI** | 8080 | Interface de gestion Kafka |
| **Zookeeper** | 2181 | Coordination Kafka |
| **Spark Master** | 8081 | Orchestrateur Spark |
| **Spark Workers** | - | 2 workers pour traitement distribuÃ© |
| **Airflow** | 8082 | Orchestration de workflows (admin/admin) |
| **PostgreSQL** | 5432 | MÃ©tadonnÃ©es Airflow + MLflow |
| **Redis** | 6379 | Broker Celery + Cache API |
| **MLflow** | 5000 | Tracking des expÃ©riences ML |
| **Prometheus** | 9090 | Collecte de mÃ©triques |
| **Grafana** | 3000 | Visualisation (admin/admin) |
| **FastAPI** | 8000 | API de service |
| **FastAPI Docs** | 8000/docs | Documentation interactive |

### Architecture des DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚ â”€â”€â–º Streaming Events (view, click, rating)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Spark    â”‚ â”€â”€â–º Traitement distribuÃ©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lakehouse  â”‚ â”€â”€â–º Bronze â†’ Silver â†’ Gold
â”‚  (Delta)    â”‚     (Raw â†’ Cleaned â†’ Aggregated)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚ â”€â”€â–º API REST pour recommandations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layers du Lakehouse

- **Bronze**: DonnÃ©es brutes (CSV, JSON) - Stockage Parquet
- **Silver**: DonnÃ©es nettoyÃ©es et validÃ©es - Format Delta Lake
- **Gold**: AgrÃ©gations et rÃ©sultats ML - Format Delta Lake

---

## Installation et DÃ©marrage

### PrÃ©requis

- Docker Desktop (Windows/Mac) ou Docker Engine + Docker Compose (Linux)
- Au moins 8GB de RAM disponible
- 20GB d'espace disque libre
- Python 3.6+ (pour les scripts de validation)

### DÃ©marrage Rapide

**Windows (PowerShell):**
```powershell
.\init.ps1
```

**Linux/Mac:**
```bash
chmod +x init.sh
./init.sh
```

Le script d'initialisation :
1. DÃ©marre PostgreSQL
2. CrÃ©e la base de donnÃ©es MLflow
3. DÃ©marre tous les services
4. Initialise Airflow

### VÃ©rification

```bash
# VÃ©rifier l'Ã©tat des services
docker-compose ps

# Tester la connectivitÃ©
docker-compose exec fastapi python test-connections.py
```

---

## Structure du Projet

```
Films-recommandation-system/
â”œâ”€â”€ docker-compose.yml              # Configuration principale
â”œâ”€â”€ docker-compose.override.yml.example
â”‚
â”œâ”€â”€ README.md                        # Documentation principale
â”œâ”€â”€ DOCUMENTATION_COMPLETE.md        # Ce fichier (rÃ©sumÃ© consolidÃ©)
â”‚
â”œâ”€â”€ init.sh / init.ps1               # Scripts d'initialisation
â”œâ”€â”€ test-connections.py              # Test de connectivitÃ©
â”œâ”€â”€ Makefile                         # Commandes utiles
â”‚
â”œâ”€â”€ api/                             # Application FastAPI
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ airflow/                         # Configuration Airflow
â”‚   â”œâ”€â”€ dags/                        # DAGs Airflow
â”‚   â”œâ”€â”€ logs/                        # Logs (gÃ©nÃ©rÃ©s)
â”‚   â”œâ”€â”€ plugins/                     # Plugins personnalisÃ©s
â”‚   â””â”€â”€ config/                      # Configuration
â”‚
â”œâ”€â”€ spark/                           # Configuration Spark
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ spark-defaults.conf
â”‚       â””â”€â”€ log4j2.properties
â”‚
â”œâ”€â”€ prometheus/                      # Configuration Prometheus
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ alerts.yml
â”‚
â”œâ”€â”€ grafana/                         # Configuration Grafana
â”‚   â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ provisioning/
â”‚
â”œâ”€â”€ mlflow/                          # Configuration MLflow
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ lakehouse/                       # Stockage des donnÃ©es
â”‚   â””â”€â”€ bronze/                      # Bronze layer
â”‚       â””â”€â”€ movielens/
â”‚           â””â”€â”€ ml-25m/
â”‚
â”œâ”€â”€ schemas/                         # DÃ©finitions de schÃ©mas
â”‚   â”œâ”€â”€ events/                      # SchÃ©mas JSON Kafka
â”‚   â””â”€â”€ lakehouse/                   # SchÃ©mas YAML tables
â”‚
â”œâ”€â”€ scripts/                         # Scripts utilitaires
â”‚   â”œâ”€â”€ bootstrap_bronze_movielens_25m.py  # Bootstrap dataset
â”‚   â”œâ”€â”€ validate_bronze_presence.py        # Validation
â”‚   â”œâ”€â”€ create-kafka-topics.sh/.ps1
â”‚   â”œâ”€â”€ check-services.sh/.ps1
â”‚   â”œâ”€â”€ backup-data.sh/.ps1
â”‚   â”œâ”€â”€ cleanup.sh/.ps1
â”‚   â”œâ”€â”€ restart-services.ps1
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ examples/                        # Exemples de code
    â”œâ”€â”€ kafka_producer_example.py
    â”œâ”€â”€ kafka_consumer_example.py
    â”œâ”€â”€ spark_kafka_example.py
    â”œâ”€â”€ mlflow_example.py
    â”œâ”€â”€ fastapi_kafka_integration.py
    â””â”€â”€ README.md
```

---

## Connexions entre Services

### RÃ©seau Docker

Tous les services sont connectÃ©s au rÃ©seau `bigdata-network` et communiquent via leurs noms d'hÃ´te.

### Connexions par Service

**Kafka:**
- Zookeeper: `zookeeper:2181`
- Bootstrap Servers (interne): `kafka:29092`
- Bootstrap Servers (externe): `localhost:9092`

**Spark:**
- Master URL: `spark://spark-master:7077`
- Lakehouse: `/lakehouse` (montÃ© dans tous les conteneurs)

**Airflow:**
- PostgreSQL: `postgres:5432` (user: `airflow`, password: `airflow`, db: `airflow`)
- Redis: `redis:6379/0` (Celery broker)
- Spark: `spark://spark-master:7077`
- Kafka: `kafka:29092`

**PostgreSQL:**
- Port: `5432`
- User: `airflow`
- Password: `airflow`
- Databases: `airflow`, `mlflow`

**Redis:**
- Host: `redis`
- Port: `6379`
- Database 0: Broker Celery
- Database 1+: Cache FastAPI

**MLflow:**
- Backend Store: `postgresql://airflow:airflow@postgres:5432/mlflow`
- Artifact Store: `/mlflow/artifacts`
- Tracking URI: `http://mlflow:5000` (interne) ou `http://localhost:5000` (externe)

**FastAPI:**
- PostgreSQL: `postgres:5432`
- Redis: `redis:6379`
- Kafka: `kafka:29092`
- MLflow: `http://mlflow:5000`
- Lakehouse: `/lakehouse`

**Prometheus:**
- Scrape tous les services sur leurs ports respectifs

**Grafana:**
- Datasource: `http://prometheus:9090`

### Variables d'Environnement ClÃ©s

**FastAPI:**
```
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow
REDIS_HOST=redis
REDIS_PORT=6379
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
MLFLOW_TRACKING_URI=http://mlflow:5000
LAKEHOUSE_PATH=/lakehouse
```

**Airflow:**
```
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres/airflow
```

---

## Step 1: Data Contracts

### Use Cases

1. **UC1: Top-K Personalized Recommendations**
   - GÃ©nÃ©ration de recommandations personnalisÃ©es avec ALS (Alternating Least Squares)
   - Traitement batch (mise Ã  jour quotidienne/hebdomadaire)

2. **UC2: Trending Now**
   - Identification des films tendances basÃ©e sur les interactions rÃ©centes
   - Mise Ã  jour quasi temps rÃ©el (toutes les quelques minutes)

3. **UC3: Hybrid Reranking**
   - Combinaison des recommandations ALS avec les signaux de tendance
   - RÃ©ponse API temps rÃ©el (< 100ms)

### Conventions de Nommage

- **Fichiers/Dossiers**: `snake_case`
- **Tables**: `snake_case` avec prÃ©fixe de layer (ex: `bronze_events_views_raw`)
- **Colonnes**: `snake_case`
- **Topics Kafka**: `snake_case` (ex: `events_views`, `events_clicks`, `events_ratings`)

### SchÃ©mas Kafka Events

**Ã‰vÃ©nements communs (tous les types):**
- `event_id` (UUID, requis)
- `event_type` (enum: "view", "click", "rating", requis)
- `event_ts` (ISO-8601 string, requis)
- `user_id` (integer, requis)
- `movie_id` (integer, requis)

**View Event** (`events_views`):
- Champs optionnels: `session_id`, `page_url`, `device_type`

**Click Event** (`events_clicks`):
- Champs optionnels: `click_type`, `session_id`, `referrer`

**Rating Event** (`events_ratings`):
- `rating` (float 0.5-5.0, requis)
- Champs optionnels: `review_text` (max 5000 chars)

### SchÃ©mas Lakehouse

**Bronze Layer** (DonnÃ©es brutes):
- `bronze_movielens_ratings_raw`
- `bronze_movielens_movies_raw`
- `bronze_movielens_tags_raw`
- `bronze_events_views_raw`
- `bronze_events_clicks_raw`
- `bronze_events_ratings_raw`
- Format: Parquet
- Partition: `ingestion_date`

**Silver Layer** (DonnÃ©es nettoyÃ©es):
- `silver_ratings`
- `silver_movies`
- `silver_tags`
- `silver_events_views`
- `silver_events_clicks`
- `silver_events_ratings`
- Format: Delta Lake
- Partition: `event_date`

**Gold Layer** (AgrÃ©gations):
- `gold_recommendations_als`
- `gold_trending_now`
- `gold_recommendations_final`
- Format: Delta Lake
- Partition: `computed_date`

### RÃ¨gles de QualitÃ© des DonnÃ©es

1. **ComplÃ©tude**: Champs requis non null
2. **ValiditÃ©**: IDs positifs, ratings 0.5-5.0, timestamps valides
3. **UnicitÃ©**: Event IDs uniques, dÃ©duplication dans Silver
4. **CohÃ©rence**: RÃ©fÃ©rences valides (movies/users existent)
5. **FraÃ®cheur**: Ingestion Bronze < 5 min, Silver < 1h, Gold quotidien

### Gestion des Erreurs

- Ã‰vÃ©nements invalides â†’ Dead-letter queue (`events_dlq`)
- RÃ©fÃ©rences manquantes â†’ CrÃ©ation de placeholders
- Duplicatas â†’ Conservation du plus rÃ©cent
- Ã‰checs qualitÃ© > 5% â†’ Ã‰chec du job ETL

### SchÃ©mas JSON Disponibles

Les schÃ©mas JSON pour les Ã©vÃ©nements Kafka sont disponibles dans :
- `schemas/events/view_event.schema.json`
- `schemas/events/click_event.schema.json`
- `schemas/events/rating_event.schema.json`

### SchÃ©mas YAML Lakehouse Disponibles

Les spÃ©cifications de schÃ©mas pour les tables lakehouse sont disponibles dans :
- `schemas/lakehouse/bronze_tables.yml`
- `schemas/lakehouse/silver_tables.yml`
- `schemas/lakehouse/gold_tables.yml`

---

## Step 2: Bootstrap Bronze Layer

### Objectif

TÃ©lÃ©charger et extraire le dataset MovieLens 25M dans la couche Bronze.

### Dataset

- **Source**: https://files.grouplens.org/datasets/movielens/ml-25m.zip
- **Taille**: ~250 MB compressÃ©, ~1.5 GB dÃ©compressÃ©
- **Fichiers**: `ratings.csv` (~25M), `movies.csv` (~62K), `tags.csv` (~1M), `links.csv`

### Bootstrap

**Toutes plateformes (Python - RecommandÃ©):**
```bash
# Avec Makefile
make bootstrap_bronze

# Ou directement
python scripts/bootstrap_bronze_movielens_25m.py

# Forcer le re-tÃ©lÃ©chargement
python scripts/bootstrap_bronze_movielens_25m.py --force
```

**Linux/Mac (Bash - Alternative):**
```bash
./scripts/bootstrap_bronze_movielens_25m.sh
```

### Validation

```bash
# Avec Makefile
make validate_bronze

# Ou directement
python scripts/validate_bronze_presence.py
```

### Structure RÃ©sultante

```
lakehouse/bronze/movielens/ml-25m/
â”œâ”€â”€ _manifest.json      # MÃ©tadonnÃ©es du dataset
â”œâ”€â”€ ratings.csv         # ~25M ratings
â”œâ”€â”€ movies.csv          # ~62K movies
â”œâ”€â”€ tags.csv            # ~1M tags
â”œâ”€â”€ links.csv           # Liens externes
â”œâ”€â”€ genome-scores.csv   # (optionnel)
â””â”€â”€ genome-tags.csv     # (optionnel)
```

### Manifest File

Le fichier `_manifest.json` contient :
- `dataset_name`: "movielens"
- `dataset_version`: "ml-25m"
- `source_url`: URL de tÃ©lÃ©chargement
- `ingestion_ts`: Timestamp ISO-8601
- `ingestion_date`: Date d'ingestion
- `files`: Liste des fichiers avec tailles, row counts, checksums MD5

### CritÃ¨res d'Acceptation

âœ… Tous les fichiers CSV requis prÃ©sents
âœ… Manifest file prÃ©sent et valide
âœ… Validation script passe (exit code 0)
âœ… Fichiers accessibles depuis conteneurs (`/lakehouse`)

### AccÃ¨s depuis Conteneurs

```bash
# VÃ©rifier depuis Spark
docker-compose exec spark-master ls -lh /lakehouse/bronze/movielens/ml-25m/

# VÃ©rifier depuis Airflow
docker-compose exec airflow-worker ls -lh /lakehouse/bronze/movielens/ml-25m/
```

---

## Scripts Utilitaires

### Scripts Disponibles

1. **Bootstrap Dataset**
   - `bootstrap_bronze_movielens_25m.py` (Python, cross-platform)
   - `bootstrap_bronze_movielens_25m.sh` (Bash, Linux/Mac)

2. **Validation**
   - `validate_bronze_presence.py` (Python, cross-platform)

3. **Gestion Kafka**
   - `create-kafka-topics.sh/.ps1` - CrÃ©er les topics Kafka

4. **VÃ©rification Services**
   - `check-services.sh/.ps1` - VÃ©rifier l'Ã©tat des services

5. **Maintenance**
   - `backup-data.sh/.ps1` - Sauvegarder donnÃ©es et configs
   - `cleanup.sh/.ps1` - Nettoyer fichiers temporaires
   - `restart-services.ps1` - RedÃ©marrer services sÃ©quentiellement

### Makefile Commands

```bash
make bootstrap_bronze  # Bootstrap MovieLens dataset
make validate_bronze    # Valider Bronze layer
make docs               # Ouvrir documentation
make clean              # Nettoyer fichiers temporaires
```

Voir `scripts/README.md` pour la documentation complÃ¨te des scripts.

---

## Exemples de Code

### Kafka

**Producteur** (`kafka_producer_example.py`):
```python
from kafka import KafkaProducer
producer = KafkaProducer(bootstrap_servers='localhost:9092')
producer.send('events_ratings', value=json.dumps(event).encode())
```

**Consommateur** (`kafka_consumer_example.py`):
```python
from kafka import KafkaConsumer
consumer = KafkaConsumer('events_ratings', bootstrap_servers='localhost:9092')
for message in consumer:
    process_event(message.value)
```

### Spark + Kafka Streaming

**Exemple** (`spark_kafka_example.py`):
- Lecture depuis Kafka
- Traitement streaming
- Ã‰criture Delta Lake
- AgrÃ©gations par fenÃªtre temporelle

### MLflow

**Exemple** (`mlflow_example.py`):
- EntraÃ®nement modÃ¨les ALS
- Tracking hyperparamÃ¨tres et mÃ©triques
- Enregistrement modÃ¨les
- Comparaison configurations

### FastAPI + Kafka

**Exemple** (`fastapi_kafka_integration.py`):
- Endpoints pour ratings et Ã©vÃ©nements
- IntÃ©gration Kafka asynchrone
- Documentation Swagger automatique

Voir `examples/README.md` pour la documentation complÃ¨te des exemples.

---

## Configuration

### Kafka

- Port interne: `kafka:29092`
- Port externe: `localhost:9092`
- Topics: `events_views`, `events_clicks`, `events_ratings`

### Spark

- Master URL: `spark://spark-master:7077`
- Workers: 2 workers (2GB RAM, 2 cores chacun)
- Lakehouse: `/lakehouse` dans tous les conteneurs
- Format: Delta Lake configurÃ©

### Airflow

- Executor: CeleryExecutor
- Broker: Redis (`redis:6379/0`)
- Database: PostgreSQL (`postgres:5432`)
- DAGs: `airflow/dags/`
- Credentials: admin/admin

### MLflow

- Backend Store: PostgreSQL (`mlflow` database)
- Artifact Store: Volume Docker `mlflow-artifacts`
- Tracking URI: `http://mlflow:5000`

### FastAPI

- Variables d'environnement dans `docker-compose.yml`
- Documentation: `http://localhost:8000/docs`
- Health check: `http://localhost:8000/health`

---

## Monitoring

### Prometheus

- Port: `9090`
- Scrape tous les services automatiquement
- Configuration: `prometheus/prometheus.yml`
- Alertes: `prometheus/alerts.yml`

### Grafana

- Port: `3000`
- Credentials: admin/admin
- Datasource: Prometheus (auto-configurÃ©)
- Dashboards: `grafana/dashboards/`

### Kafka UI

- Port: `8080`
- Interface web pour gÃ©rer Kafka
- Visualisation des topics et messages

---

## DÃ©pannage

### Service ne dÃ©marre pas

1. VÃ©rifier les logs: `docker-compose logs <service-name>`
2. VÃ©rifier les dÃ©pendances dans `docker-compose.yml`
3. VÃ©rifier que les ports ne sont pas utilisÃ©s

### Airflow ne se connecte pas Ã  PostgreSQL

1. VÃ©rifier que PostgreSQL est dÃ©marrÃ©: `docker-compose ps postgres`
2. VÃ©rifier les logs: `docker-compose logs postgres`
3. RÃ©initialiser: `docker-compose up airflow-init`

### MLflow ne se connecte pas Ã  PostgreSQL

1. VÃ©rifier que la DB existe:
   ```bash
   docker-compose exec postgres psql -U airflow -c "\l" | grep mlflow
   ```
2. CrÃ©er si nÃ©cessaire:
   ```bash
   docker-compose exec postgres psql -U airflow -c "CREATE DATABASE mlflow;"
   ```

### ProblÃ¨mes de mÃ©moire

- RÃ©duire nombre de workers Spark
- RÃ©duire mÃ©moire workers: `SPARK_WORKER_MEMORY=1g`
- ArrÃªter services non essentiels

### Kafka ne dÃ©marre pas

1. VÃ©rifier Zookeeper: `docker-compose ps zookeeper`
2. VÃ©rifier les logs: `docker-compose logs kafka zookeeper`
3. Supprimer volumes corrompus si nÃ©cessaire

---

## Commandes Utiles

### Gestion Docker

```bash
# VÃ©rifier l'Ã©tat
docker-compose ps

# Voir les logs
docker-compose logs -f <service-name>

# RedÃ©marrer un service
docker-compose restart <service-name>

# ArrÃªter tout
docker-compose down

# ArrÃªter et supprimer volumes (âš ï¸ supprime donnÃ©es)
docker-compose down -v
```

### ExÃ©cuter dans un conteneur

```bash
# Shell Spark
docker-compose exec spark-master bash

# CrÃ©er topic Kafka
docker-compose exec kafka kafka-topics --create \
  --topic events_views \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

# Tester connectivitÃ©
docker-compose exec fastapi python test-connections.py
```

### Spark Jobs

```bash
# Soumettre job Spark
docker-compose exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  /path/to/your/script.py
```

---

## Prochaines Ã‰tapes

### DÃ©veloppement

1. âœ… **Step 1**: Data Contracts dÃ©finis
2. âœ… **Step 2**: Bootstrap Bronze layer complÃ©tÃ©
3. â­ï¸ **Step 3**: ImplÃ©menter ETL Bronze â†’ Silver (Spark)
4. â­ï¸ **Step 4**: Ingestion streaming Kafka â†’ Bronze/Silver
5. â­ï¸ **Step 5**: Pipelines ML (ALS, Trending, Hybrid)

### Actions RecommandÃ©es

1. **CrÃ©er DAGs Airflow** personnalisÃ©s dans `airflow/dags/`
2. **DÃ©velopper logique recommandation** dans Spark
3. **Configurer pipelines Kafka** pour streaming
4. **DÃ©velopper API FastAPI** avec endpoints mÃ©tier
5. **CrÃ©er dashboards Grafana** personnalisÃ©s
6. **Configurer MLflow** pour tracking modÃ¨les
7. **Utiliser exemples** dans `examples/` comme point de dÃ©part

### Workflow de DÃ©veloppement

1. DÃ©marrer systÃ¨me: `.\init.ps1` ou `./init.sh`
2. Bootstrap donnÃ©es: `make bootstrap_bronze`
3. CrÃ©er topics Kafka: `.\scripts\create-kafka-topics.ps1`
4. Explorer exemples: `examples/`
5. DÃ©velopper DAGs: `airflow/dags/`
6. Tester API: `http://localhost:8000/docs`

---

## Support

Pour toute question ou problÃ¨me:
1. Consulter les logs: `docker-compose logs <service-name>`
2. VÃ©rifier la documentation officielle de chaque outil
3. Consulter les sections DÃ©pannage ci-dessus
4. VÃ©rifier que Docker a assez de ressources

---

**DerniÃ¨re mise Ã  jour**: DÃ©cembre 2025
**Version**: 1.0
**Statut**: Step 1 & Step 2 complÃ©tÃ©s âœ…

