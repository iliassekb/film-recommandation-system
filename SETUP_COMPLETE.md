# ‚úÖ Configuration Termin√©e

Votre environnement Big Data pour le syst√®me de recommandation de films est maintenant configur√© !

## üì¶ Services Configur√©s

Tous les services suivants sont configur√©s et pr√™ts √† √™tre d√©marr√©s :

‚úÖ **Kafka** + Zookeeper + Kafka UI
- Streaming de donn√©es en temps r√©el
- Interface de gestion via Kafka UI

‚úÖ **Spark** (Master + 2 Workers)
- Traitement distribu√© des donn√©es
- Configuration Delta Lake

‚úÖ **Airflow** (Webserver + Scheduler + Worker Celery)
- Orchestration de workflows
- Base de donn√©es PostgreSQL
- Broker Redis

‚úÖ **PostgreSQL**
- M√©tadonn√©es Airflow
- M√©tadonn√©es MLflow

‚úÖ **Redis**
- Broker Celery pour Airflow
- Cache pour l'API

‚úÖ **MLflow**
- Tracking des exp√©riences ML
- Stockage des artifacts

‚úÖ **Prometheus + Grafana**
- Monitoring et observabilit√©
- Dashboards personnalisables

‚úÖ **FastAPI**
- API de service pour les recommandations
- Documentation automatique

‚úÖ **Lakehouse**
- Stockage centralis√© Delta/Parquet
- Accessible par tous les services

## üöÄ Prochaines √âtapes

### 1. D√©marrer le syst√®me

```powershell
# Windows
.\init.ps1

# Linux/Mac
chmod +x init.sh
./init.sh
```

### 2. V√©rifier que tout fonctionne

```bash
# V√©rifier l'√©tat des services
docker-compose ps

# Tester la connectivit√©
docker-compose exec fastapi python test-connections.py
```

### 3. Acc√©der aux interfaces

- **Airflow** : http://localhost:8082 (admin/admin)
- **Kafka UI** : http://localhost:8080
- **Spark Master** : http://localhost:8081
- **MLflow** : http://localhost:5000
- **Grafana** : http://localhost:3000 (admin/admin)
- **FastAPI Docs** : http://localhost:8000/docs

## üìö Documentation

- **[README.md](README.md)** : Documentation compl√®te
- **[QUICK_START.md](QUICK_START.md)** : Guide de d√©marrage rapide
- **[CONNECTIONS.md](CONNECTIONS.md)** : Guide des connexions entre services
- **[PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md)** : Structure du projet

## üîß Personnalisation

### Ajouter des DAGs Airflow

Placez vos fichiers Python dans `airflow/dags/`

### D√©velopper l'API

Modifiez `api/main.py` pour ajouter vos endpoints

### Configurer Spark

Ajustez `spark/config/spark-defaults.conf` selon vos besoins

### Cr√©er des dashboards Grafana

Ajoutez vos dashboards dans `grafana/dashboards/`

## üéØ Exemples d'Utilisation

### Cr√©er un topic Kafka

```bash
docker-compose exec kafka kafka-topics --create \
  --topic films \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1
```

### Soumettre un job Spark

```bash
docker-compose exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --class your.main.Class \
  your-app.jar
```

### Utiliser MLflow depuis Python

```python
import mlflow
mlflow.set_tracking_uri("http://localhost:5000")
mlflow.start_run()
# Votre code d'entra√Ænement
mlflow.log_metric("accuracy", 0.95)
mlflow.end_run()
```

## ‚ö†Ô∏è Notes Importantes

1. **M√©moire** : Assurez-vous d'avoir au moins 8GB de RAM disponible
2. **Ports** : V√©rifiez que les ports ne sont pas d√©j√† utilis√©s
3. **Volumes** : Les donn√©es sont persist√©es dans des volumes Docker
4. **Initialisation** : Les services `airflow-init` et `mlflow-init` s'ex√©cutent une seule fois

## üÜò Support

En cas de probl√®me :

1. V√©rifiez les logs : `docker-compose logs <service-name>`
2. Consultez la section D√©pannage du README
3. V√©rifiez que Docker a assez de ressources

## üéâ Pr√™t √† Commencer !

Votre environnement est maintenant pr√™t. Bon d√©veloppement !

