"""
Exemple d'utilisation de MLflow pour tracker les exp√©riences de recommandation
Ce script montre comment utiliser MLflow pour enregistrer des mod√®les et m√©triques
"""

import mlflow
import mlflow.sklearn
import mlflow.spark
from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator
import pandas as pd
import numpy as np
from datetime import datetime

# Configuration MLflow
MLFLOW_TRACKING_URI = "http://mlflow:5000"
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

def create_spark_session():
    """Cr√©er une session Spark"""
    spark = SparkSession.builder \
        .appName("FilmRecommendationMLflow") \
        .config("spark.master", "spark://spark-master:7077") \
        .getOrCreate()
    
    return spark

def train_als_model(spark, ratings_df, rank=10, max_iter=10, reg_param=0.1):
    """
    Entra√Æner un mod√®le ALS (Alternating Least Squares) pour la recommandation
    
    Args:
        spark: SparkSession
        ratings_df: DataFrame Spark avec colonnes user_id, film_id, rating
        rank: Nombre de facteurs latents
        max_iter: Nombre d'it√©rations
        reg_param: Param√®tre de r√©gularisation
    
    Returns:
        Mod√®le ALS entra√Æn√©
    """
    # Diviser en train/test
    (training, test) = ratings_df.randomSplit([0.8, 0.2])
    
    # Cr√©er et entra√Æner le mod√®le ALS
    als = ALS(
        maxIter=max_iter,
        regParam=reg_param,
        rank=rank,
        userCol="user_id",
        itemCol="film_id",
        ratingCol="rating",
        coldStartStrategy="drop"
    )
    
    model = als.fit(training)
    
    # Faire des pr√©dictions
    predictions = model.transform(test)
    
    # √âvaluer le mod√®le
    evaluator = RegressionEvaluator(
        metricName="rmse",
        labelCol="rating",
        predictionCol="prediction"
    )
    
    rmse = evaluator.evaluate(predictions)
    
    return model, rmse, predictions

def log_experiment_with_mlflow(spark, ratings_df, experiment_name="FilmRecommendation"):
    """
    Entra√Æner un mod√®le et logger l'exp√©rience avec MLflow
    
    Args:
        spark: SparkSession
        ratings_df: DataFrame Spark avec les ratings
        experiment_name: Nom de l'exp√©rience MLflow
    """
    # Cr√©er ou r√©cup√©rer l'exp√©rience
    try:
        experiment_id = mlflow.create_experiment(experiment_name)
    except:
        experiment = mlflow.get_experiment_by_name(experiment_name)
        experiment_id = experiment.experiment_id
    
    mlflow.set_experiment(experiment_name)
    
    # Hyperparam√®tres √† tester
    ranks = [5, 10, 20]
    reg_params = [0.01, 0.1, 1.0]
    
    best_rmse = float('inf')
    best_model = None
    
    for rank in ranks:
        for reg_param in reg_params:
            with mlflow.start_run():
                # Entra√Æner le mod√®le
                model, rmse, predictions = train_als_model(
                    spark, ratings_df, 
                    rank=rank, 
                    reg_param=reg_param
                )
                
                # Logger les param√®tres
                mlflow.log_param("rank", rank)
                mlflow.log_param("reg_param", reg_param)
                mlflow.log_param("algorithm", "ALS")
                
                # Logger les m√©triques
                mlflow.log_metric("rmse", rmse)
                
                # Logger le mod√®le Spark
                mlflow.spark.log_model(
                    model,
                    "als_model",
                    registered_model_name="FilmRecommendationALS"
                )
                
                # Logger des exemples de pr√©dictions
                sample_predictions = predictions.select("user_id", "film_id", "rating", "prediction").limit(100)
                sample_predictions_pd = sample_predictions.toPandas()
                mlflow.log_table(sample_predictions_pd, "sample_predictions.json")
                
                # Tags
                mlflow.set_tag("model_type", "collaborative_filtering")
                mlflow.set_tag("framework", "pyspark")
                mlflow.set_tag("date", datetime.now().strftime("%Y-%m-%d"))
                
                print(f"‚úÖ Mod√®le entra√Æn√© - Rank: {rank}, Reg: {reg_param}, RMSE: {rmse:.4f}")
                
                # Garder le meilleur mod√®le
                if rmse < best_rmse:
                    best_rmse = rmse
                    best_model = model
    
    print(f"\nüèÜ Meilleur mod√®le - RMSE: {best_rmse:.4f}")
    return best_model

def load_and_use_model(model_uri):
    """
    Charger un mod√®le depuis MLflow et l'utiliser
    
    Args:
        model_uri: URI du mod√®le dans MLflow (ex: "models:/FilmRecommendationALS/1")
    """
    # Charger le mod√®le
    model = mlflow.spark.load_model(model_uri)
    
    # Utiliser le mod√®le pour faire des recommandations
    # (exemple avec un DataFrame de users)
    # recommendations = model.recommendForAllUsers(10)
    
    return model

def main():
    """Fonction principale - Exemple d'utilisation"""
    print("üöÄ Exemple d'utilisation de MLflow avec Spark")
    print(f"üìä MLflow Tracking URI: {MLFLOW_TRACKING_URI}")
    
    # Cr√©er la session Spark
    spark = create_spark_session()
    
    # Charger les donn√©es depuis le lakehouse
    # ratings_df = spark.read.format("delta").load("/lakehouse/film_ratings")
    
    # Pour l'exemple, cr√©er des donn√©es fictives
    print("üìù Cr√©ation de donn√©es d'exemple...")
    data = [
        (1, 1, 4.5), (1, 2, 3.0), (1, 3, 5.0),
        (2, 1, 3.5), (2, 2, 4.0), (2, 4, 4.5),
        (3, 1, 5.0), (3, 3, 4.0), (3, 4, 3.5),
    ] * 100  # R√©p√©ter pour avoir plus de donn√©es
    
    ratings_df = spark.createDataFrame(
        data,
        ["user_id", "film_id", "rating"]
    )
    
    print(f"üìä Nombre de ratings: {ratings_df.count()}")
    
    # Entra√Æner et logger avec MLflow
    print("\nüî¨ D√©marrage de l'exp√©rience MLflow...")
    best_model = log_experiment_with_mlflow(spark, ratings_df)
    
    print("\n‚úÖ Exp√©rience termin√©e!")
    print(f"üìà Consultez les r√©sultats sur: {MLFLOW_TRACKING_URI}")
    
    spark.stop()

if __name__ == "__main__":
    main()

