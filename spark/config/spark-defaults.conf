spark.master                     spark://spark-master:7077
spark.app.name                   FilmRecommendationSystem
spark.executor.memory            2g
spark.driver.memory              1g
spark.executor.cores             2
spark.sql.warehouse.dir          /lakehouse/warehouse

# NOTE: Delta Lake integration is disabled in this image by default because
# the Delta JARs are not bundled with the apache/spark-py:latest container.
# The following settings force Spark to look for Delta classes which are
# missing and cause ClassNotFoundException when running jobs locally.
#
# If you later add Delta dependencies (e.g. via --packages io.delta:delta-core_2.12:<version>)
# you can uncomment these lines again.
# spark.sql.extensions              io.delta.sql.DeltaSparkSessionExtension
# spark.sql.catalog.spark_catalog  org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.serializer                  org.apache.spark.serializer.KryoSerializer
spark.sql.adaptive.enabled       true
spark.sql.adaptive.coalescePartitions.enabled true
spark.driver.host                 spark-master
spark.driver.port                 7077
spark.network.timeout             600s
spark.executor.heartbeatInterval 60s

