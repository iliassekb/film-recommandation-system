#!/bin/bash
# Script pour ex√©cuter le streaming Kafka ‚Üí Console en mode LOCAL
# Mode local = ex√©cution sur le driver uniquement (pas besoin de workers ou de JARs install√©s)
# Utile pour tester avec des ressources limit√©es

KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-"kafka:29092"}
STORAGE_FORMAT=${STORAGE_FORMAT:-"parquet"}
LAKEHOUSE_PATH=${LAKEHOUSE_PATH:-"/data"}

echo "üöÄ D√©marrage du streaming Kafka ‚Üí Console (MODE LOCAL)"
echo "   Kafka: $KAFKA_BOOTSTRAP_SERVERS"
echo "   Mode: LOCAL (ex√©cution sur driver uniquement)"
echo "   Topics: events_views, events_clicks, events_ratings"
echo ""
echo "üì° Les √©v√©nements seront affich√©s dans la console toutes les 2 secondes"
echo "   Appuyez sur Ctrl+C pour arr√™ter"
echo ""
echo "‚ÑπÔ∏è  Mode LOCAL utilise --packages pour t√©l√©charger automatiquement les JARs Kafka"
echo "   Pas besoin d'installer les JARs manuellement"
echo ""

# Mode local - ex√©cute tout sur le driver avec --packages
docker-compose exec spark-master bash -c "
    export KAFKA_BOOTSTRAP_SERVERS=$KAFKA_BOOTSTRAP_SERVERS && \
    export STORAGE_FORMAT=$STORAGE_FORMAT && \
    export LAKEHOUSE_PATH=$LAKEHOUSE_PATH && \
    /opt/spark/bin/spark-submit \
        --master local[2] \
        --deploy-mode client \
        --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0 \
        --conf spark.sql.adaptive.enabled=true \
        --conf spark.sql.adaptive.coalescePartitions.enabled=true \
        /opt/spark/jobs/stream_kafka_console.py
"

